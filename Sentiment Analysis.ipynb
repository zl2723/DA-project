{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NRC sentiment analysis for Amazon laptop lexicons based on customer reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nrc_data():\n",
    "    nrc_bigram = \"/Users/zhen/Desktop/Amazon-laptops-electronics-reviews-AFFLEX-NEGLEX-bigrams.txt\"\n",
    "    nrc_unigram = \"/Users/zhen/Desktop/Amazon-laptops-electronics-reviews-AFFLEX-NEGLEX-unigrams.txt\"\n",
    "    count=0\n",
    "    emotion_dict=dict()\n",
    "    with open (nrc_unigram,'r') as u:\n",
    "        all_lines = list()\n",
    "        for line in u:\n",
    "#         for line1, line2 in zip(b,u):\n",
    "#             if count < 46:\n",
    "#                 count+=1\n",
    "#                 continue\n",
    "            line = line.strip().split('\\t')\n",
    "#             line2 = line2.strip().split('\\t')\n",
    "            if int(line[2]) == 1:\n",
    "                if emotion_dict.get(line[0]):\n",
    "                    emotion_dict[line[0]].append(line[1])\n",
    "                else:\n",
    "                    emotion_dict[line[0]] = [line[1]]\n",
    "    \n",
    "    return emotion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'squealing': ['-2.584'],\n",
       " 're-stocking': ['-2.584'],\n",
       " 'miserable_NEG': ['-2.584'],\n",
       " 'warrenty_NEG': ['-2.584'],\n",
       " 'mbit/sec': ['-2.584'],\n",
       " 'inno': ['-2.584'],\n",
       " 'joy_NEGFIRST': ['-2.584'],\n",
       " '3-com': ['-2.584'],\n",
       " 'locksmith': ['-2.584'],\n",
       " 'poorest': ['-2.584'],\n",
       " 'jiggled': ['-2.584'],\n",
       " 'successfully_NEGFIRST': ['-2.584'],\n",
       " 'peril': ['-2.584'],\n",
       " 'microhub': ['-2.584'],\n",
       " 'dane-elec': ['-2.584'],\n",
       " 'poloroid': ['-2.584'],\n",
       " 'yr_NEG': ['-2.584'],\n",
       " 'process_NEGFIRST': ['-2.584'],\n",
       " 'helping_NEGFIRST': ['-2.584'],\n",
       " 'unacceptable_NEG': ['-2.584'],\n",
       " 'condescending': ['-2.584'],\n",
       " \"lexmark's\": ['-2.584'],\n",
       " 'bluescreens': ['-2.584'],\n",
       " 'denies': ['-2.584'],\n",
       " 'merchandise_NEG': ['-2.584'],\n",
       " 'manufactured_NEGFIRST': ['-2.584'],\n",
       " 'n3': ['-2.584'],\n",
       " 'liars': ['-2.584'],\n",
       " 'wah': ['-2.738'],\n",
       " 'neophyte_NEG': ['-2.738'],\n",
       " \"winxp's\": ['-2.738'],\n",
       " '310x': ['-2.738'],\n",
       " 'spyder2': ['-2.738'],\n",
       " 'jamcam': ['-2.738'],\n",
       " 'bait': ['-2.738'],\n",
       " 'zire72': ['-2.738'],\n",
       " 'battary': ['-2.738'],\n",
       " 'sparking': ['-2.738'],\n",
       " 'thermal_NEG': ['-2.738'],\n",
       " 'reimbursed_NEG': ['-2.738'],\n",
       " 'urc': ['-2.738'],\n",
       " 'cd-rs_NEG': ['-2.738'],\n",
       " 'telling_NEGFIRST': ['-2.738'],\n",
       " '750g': ['-2.738'],\n",
       " '700z': ['-2.872'],\n",
       " 'durabook': ['-2.872'],\n",
       " 'istanbul': ['-2.872'],\n",
       " 'n19': ['-2.872'],\n",
       " '11a': ['-2.990'],\n",
       " 'rotten': ['-2.990'],\n",
       " 'fxa47': ['-3.190'],\n",
       " 'unreliability': ['-3.277'],\n",
       " 'â€œ': ['-3.500'],\n",
       " 'refund_NEGFIRST': ['-3.683']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nrc_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_analyzer(text,emotion_dict=emotion_dict):\n",
    "    #Set up the result dictionary\n",
    "    emotions = {x for y in emotion_dict.values() for x in y}\n",
    "    emotion_count = dict()\n",
    "    for emotion in emotions:\n",
    "        emotion_count[emotion] = 0\n",
    "\n",
    "    #Analyze the text and normalize by total number of words\n",
    "    total_words = len(text.split())\n",
    "    for word in text.split():\n",
    "        if emotion_dict.get(word):\n",
    "            for emotion in emotion_dict.get(word):\n",
    "                emotion_count[emotion] += 1/len(text.split())\n",
    "    return emotion_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
